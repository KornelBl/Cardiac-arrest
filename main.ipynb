{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from trainer import train_evaluate\n",
    "from feature_selection import get_k_best\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def get_data(files):\n",
    "    data_matrix = np.loadtxt(files[0], dtype='i', delimiter='\\t')\n",
    "    data_matrix = data_matrix.T\n",
    "\n",
    "    last_col = [0] * len(data_matrix)\n",
    "    data_matrix = np.column_stack((data_matrix, last_col))\n",
    "\n",
    "    for x in range(len(files) - 1):\n",
    "        temp_matrix = np.loadtxt(files[x + 1], dtype='i', delimiter='\\t')\n",
    "        temp_matrix = temp_matrix.T\n",
    "        last_col = [x+1] * len(temp_matrix)\n",
    "        temp_matrix = np.column_stack((temp_matrix, last_col))\n",
    "        data_matrix = np.concatenate((data_matrix, temp_matrix), axis=0)\n",
    "\n",
    "    X = data_matrix[:, :-1]\n",
    "    Y = data_matrix[:, -1]\n",
    "    return X, Y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[  5,  20, 135, ...,   1,   1,   0],\n       [  2,  18, 127, ...,   1,   1,   1],\n       [  1,  12, 164, ...,   0,   1,   0],\n       ...,\n       [  3,  15, 191, ...,   0,   0,   1],\n       [  6,  19, 208, ...,   0,   1,   0],\n       [  1,   1, 191, ...,   1,   1,   0]])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 3
    }
   ],
   "source": [
    "files = glob.glob('dataset/*.txt')\n",
    "X, Y = get_data(files)\n",
    "\n",
    "get_k_best(X,Y,10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "fvalue_selector = SelectKBest(chi2, k=10)\n",
    "fvalue_selector.fit(X, Y)\n",
    "\n",
    "rank = fvalue_selector.scores_\n",
    "top_rank = []\n",
    "indexes = rank.argsort()[-10:][::-1]\n",
    "\n",
    "for index in indexes:\n",
    "    top_rank.append(rank[index])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "layer_sizes = [100,200,350]\n",
    "momentum_values = [0, 0.9]\n",
    "max_patience = 10\n",
    "filename = \"resultaty.csv\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "100\t0\t1\t0.2521586597684159\n",
      "100\t0\t2\t0.328989898989899\n",
      "100\t0\t3\t0.3298881497905888\n",
      "100\t0\t4\t0.32852475979305246\n",
      "100\t0\t5\t0.32361320522296133\n",
      "100\t0\t6\t0.32582113821138214\n",
      "100\t0\t7\t0.2923557526484356\n",
      "100\t0\t8\t0.32871741808327176\n",
      "100\t0\t9\t0.31608474993840846\n",
      "100\t0\t10\t0.39943532889874356\n",
      "100\t0\t11\t0.2931919191919191\n",
      "100\t0\t12\t0.29544961813254494\n",
      "100\t0\t13\t0.3378354274451836\n",
      "100\t0\t14\t0.30437595466863765\n",
      "100\t0\t15\t0.3371515151515151\n",
      "100\t0\t16\t0.36718403547671846\n",
      "100\t0\t17\t0.350709534368071\n",
      "100\t0\t18\t0.3877560975609756\n",
      "100\t0\t19\t0.3848780487804878\n",
      "100\t0\t20\t0.3740044345898005\n",
      "100\t0.9\t1\t0.29189701897018966\n",
      "100\t0.9\t2\t0.4157580684897758\n",
      "100\t0.9\t3\t0.47232914510963286\n",
      "100\t0.9\t4\t0.5065479182064548\n",
      "100\t0.9\t5\t0.4814372998275437\n",
      "100\t0.9\t6\t0.4495476718403547\n",
      "100\t0.9\t7\t0.48591327913279125\n",
      "100\t0.9\t8\t0.5030238975117024\n",
      "100\t0.9\t9\t0.4601685144124169\n",
      "100\t0.9\t10\t0.4798684405025869\n",
      "100\t0.9\t11\t0.5038625277161863\n",
      "100\t0.9\t12\t0.4817038679477704\n",
      "100\t0.9\t13\t0.42618378911061844\n",
      "100\t0.9\t14\t0.4317368810051737\n",
      "200\t0\t1\t0.2493013057403301\n",
      "200\t0\t2\t0.3142636117270264\n",
      "200\t0\t3\t0.3198521803399852\n",
      "200\t0\t4\t0.31117713722591767\n",
      "200\t0\t5\t0.3491525006159152\n",
      "200\t0\t6\t0.29388765705838876\n",
      "200\t0\t7\t0.34935156442473514\n",
      "200\t0\t8\t0.33968120226656817\n",
      "200\t0\t9\t0.3352209903917221\n",
      "200\t0\t10\t0.33612712490761265\n",
      "200\t0\t11\t0.3515811776299581\n",
      "200\t0\t12\t0.3167839369302784\n",
      "200\t0\t13\t0.3704956885932496\n",
      "200\t0\t14\t0.3518270509977827\n",
      "200\t0\t15\t0.3114520817935452\n",
      "200\t0\t16\t0.3218447893569845\n",
      "200\t0\t17\t0.4108844542990885\n",
      "200\t0\t18\t0.3918314855875832\n",
      "200\t0\t19\t0.3751525006159152\n",
      "200\t0\t20\t0.4128992362650899\n",
      "200\t0\t21\t0.4089041635870904\n",
      "200\t0\t22\t0.4095629465385563\n",
      "200\t0\t23\t0.44819265829021926\n",
      "200\t0\t24\t0.39559793052475983\n",
      "200\t0\t25\t0.3696092633653609\n",
      "200\t0\t26\t0.33587780241438775\n",
      "200\t0\t27\t0.3600606060606061\n",
      "200\t0\t28\t0.3964651391968465\n",
      "200\t0\t29\t0.3720477950234048\n",
      "200\t0\t30\t0.41798669623059864\n",
      "200\t0\t31\t0.4217368810051737\n",
      "200\t0\t32\t0.41086770140428674\n",
      "200\t0\t33\t0.3937989652623799\n",
      "200\t0.9\t1\t0.29189701897018966\n",
      "200\t0.9\t2\t0.4135412663217541\n",
      "200\t0.9\t3\t0.47368169499876817\n",
      "200\t0.9\t4\t0.44148805124414886\n",
      "200\t0.9\t5\t0.4892525252525252\n",
      "200\t0.9\t6\t0.49855580192165555\n",
      "200\t0.9\t7\t0.509649174673565\n",
      "200\t0.9\t8\t0.5120891845282088\n",
      "200\t0.9\t9\t0.5285420054200543\n",
      "200\t0.9\t10\t0.5331884700665188\n",
      "200\t0.9\t11\t0.4921118502094112\n",
      "200\t0.9\t12\t0.527209657551121\n",
      "200\t0.9\t13\t0.4375215570337522\n",
      "200\t0.9\t14\t0.5409509731460952\n",
      "200\t0.9\t15\t0.5305439763488544\n",
      "200\t0.9\t16\t0.5307548657304755\n",
      "200\t0.9\t17\t0.495909830007391\n",
      "200\t0.9\t18\t0.5007484602118748\n",
      "200\t0.9\t19\t0.5609445676274945\n",
      "200\t0.9\t20\t0.5356541019955654\n",
      "200\t0.9\t21\t0.5538211382113821\n",
      "200\t0.9\t22\t0.570279871889628\n",
      "200\t0.9\t23\t0.5416452328159644\n",
      "200\t0.9\t24\t0.5274220251293421\n",
      "200\t0.9\t25\t0.5542862774082287\n",
      "200\t0.9\t26\t0.5298674550381868\n",
      "200\t0.9\t27\t0.5105636856368564\n",
      "200\t0.9\t28\t0.5298033998521803\n",
      "200\t0.9\t29\t0.5256570583887656\n",
      "200\t0.9\t30\t0.5422857846760285\n",
      "200\t0.9\t31\t0.5405094850948509\n",
      "200\t0.9\t32\t0.5347060852426706\n",
      "350\t0\t1\t0.23751810790835184\n",
      "350\t0\t2\t0.27010396649421037\n",
      "350\t0\t3\t0.30013254496181324\n",
      "350\t0\t4\t0.37244395171224437\n",
      "350\t0\t5\t0.3078935698447894\n",
      "350\t0\t6\t0.3061276176398127\n",
      "350\t0\t7\t0.342909583641291\n",
      "350\t0\t8\t0.32718255728011825\n",
      "350\t0\t9\t0.34071938901207194\n",
      "350\t0\t10\t0.3353850702143385\n",
      "350\t0\t11\t0.3593855629465387\n",
      "350\t0\t12\t0.3307341709780734\n",
      "350\t0\t13\t0.3205577728504558\n",
      "350\t0\t14\t0.38445873367824585\n",
      "350\t0\t15\t0.3949209164818921\n",
      "350\t0\t16\t0.36180783444198084\n",
      "350\t0\t17\t0.3866691303276669\n",
      "350\t0\t18\t0.38026903178122695\n",
      "350\t0\t19\t0.38559053954175904\n",
      "350\t0\t20\t0.3893279132791328\n",
      "350\t0\t21\t0.40003054939640303\n",
      "350\t0\t22\t0.41438482384823844\n",
      "350\t0\t23\t0.4071465878295147\n",
      "350\t0\t24\t0.370019709288002\n",
      "350\t0\t25\t0.38804237496920424\n",
      "350\t0\t26\t0.4046671593988667\n",
      "350\t0\t27\t0.37286720867208667\n",
      "350\t0\t28\t0.3753146095097314\n",
      "350\t0\t29\t0.40911948755851196\n",
      "350\t0\t30\t0.40264252278886425\n",
      "350\t0\t31\t0.43864547918206453\n",
      "350\t0\t32\t0.3910928800197093\n",
      "350\t0\t33\t0.36804089677260404\n",
      "350\t0\t34\t0.40732544961813255\n",
      "350\t0\t35\t0.43327666913032764\n",
      "350\t0\t36\t0.40490367085489043\n",
      "350\t0\t37\t0.44662971175166294\n",
      "350\t0\t38\t0.4532909583641291\n",
      "350\t0\t39\t0.43487903424488794\n",
      "350\t0\t40\t0.39401281103720126\n",
      "350\t0\t41\t0.409340724316334\n",
      "350\t0\t42\t0.4379610741561962\n",
      "350\t0\t43\t0.437309682187731\n",
      "350\t0\t44\t0.46772899728997297\n",
      "350\t0\t45\t0.4210652870165065\n",
      "350\t0\t46\t0.4190317812269032\n",
      "350\t0\t47\t0.4406085242670609\n",
      "350\t0\t48\t0.4404109386548411\n",
      "350\t0\t49\t0.4217388519339738\n",
      "350\t0\t50\t0.4067775314116777\n",
      "350\t0\t51\t0.468559743779256\n",
      "350\t0\t52\t0.4599679724069968\n",
      "350\t0\t53\t0.42914067504311404\n",
      "350\t0\t54\t0.45369499876816943\n",
      "350\t0\t55\t0.4157689085981769\n",
      "350\t0\t56\t0.4330820399113082\n",
      "350\t0\t57\t0.4326410445922641\n",
      "350\t0\t58\t0.38888987435328903\n",
      "350\t0\t59\t0.44353338260655334\n",
      "350\t0.9\t1\t0.29877753141167773\n",
      "350\t0.9\t2\t0.42532594235033255\n",
      "350\t0.9\t3\t0.5036536092633652\n",
      "350\t0.9\t4\t0.47391869918699187\n",
      "350\t0.9\t5\t0.5065691056910568\n",
      "350\t0.9\t6\t0.49988371520078845\n",
      "350\t0.9\t7\t0.4876777531411678\n",
      "350\t0.9\t8\t0.5121029810298103\n",
      "350\t0.9\t9\t0.5036876077851687\n",
      "350\t0.9\t10\t0.519860064055186\n",
      "350\t0.9\t11\t0.5021261394432126\n",
      "350\t0.9\t12\t0.5433747228381375\n",
      "350\t0.9\t13\t0.5220566642030058\n",
      "350\t0.9\t14\t0.5425188470066519\n",
      "350\t0.9\t15\t0.5555683665927568\n",
      "350\t0.9\t16\t0.5498275437299828\n",
      "350\t0.9\t17\t0.5354235033259424\n",
      "350\t0.9\t18\t0.5511978319783197\n",
      "350\t0.9\t19\t0.5546962305986696\n",
      "350\t0.9\t20\t0.5536048287755605\n",
      "350\t0.9\t21\t0.5622931756590293\n",
      "350\t0.9\t22\t0.5507159398866716\n",
      "350\t0.9\t23\t0.5291731953683173\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "results = pd.DataFrame(columns=[\"layer_size\",\"momentum_value\",\"feature_number\",\"score\"])\n",
    "best_score = 0\n",
    "best_matrix = []\n",
    "best_params = {}\n",
    "for layer_size in layer_sizes:\n",
    "    for momentum_value in momentum_values:\n",
    "        patience = max_patience   \n",
    "        temp_best_score = 0\n",
    "        temp_best_matrix = []\n",
    "        temp_best_params = {}\n",
    "        for feature_number in range(1,np.shape(X)[1]+1):\n",
    "            \n",
    "            score, matrix = train_evaluate(X=get_k_best(X,Y,feature_number),\n",
    "                                           Y=Y,\n",
    "                                           momentum_value=momentum_value,\n",
    "                                           layer_size=layer_size)\n",
    "            params = {\"layer_size\":layer_size,\n",
    "                      \"momentum_value\":momentum_value,\n",
    "                      \"feature_number\":feature_number,\n",
    "                      \"score\":score}\n",
    "            results = results.append(params, ignore_index=True)\n",
    "            print(f\"{layer_size}\\t{momentum_value}\\t{feature_number}\\t{score}\")   \n",
    "            if score > temp_best_score:\n",
    "                temp_best_matrix = matrix\n",
    "                temp_best_score = score\n",
    "                patience = max_patience\n",
    "                temp_best_params = params\n",
    "            else:\n",
    "                patience -= 1\n",
    "                if patience == 0:\n",
    "                    break\n",
    "        \n",
    "         \n",
    "        if temp_best_score > best_score:\n",
    "            best_matrix = temp_best_matrix\n",
    "            best_params = temp_best_params\n",
    "            \n",
    "with open(\"best_params.json\") as f:\n",
    "    json.dump(best_params,f)\n",
    "np.savetxt(\"best_matrix.txt\")\n",
    "results.to_csv(filename)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}